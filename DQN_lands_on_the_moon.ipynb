{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njb_ProuHiOe"
   },
   "source": [
    "# Graded lab: Implement DQN for LunarLander Use pythonproejct3 kernel\n",
    "\n",
    "This lab is a modified verstion of a notebookfrom the Deep RL Course on HuggingFace.\n",
    "\n",
    "In this notebook, you'll train your **Deep Q-Network (DQN) agent** to play an Atari game. Your agent controls a spaceship, the Lunar Lander, to learn how to **land correctly on the Moon**.\n",
    "\n",
    "*All your answers should be written in this notebook. You shouldnâ€™t need to write or modify any other files. The parts of code that need to be changed as labelled as TODOs in the comments. You should execute every block of code to not miss any dependency.*\n",
    "\n",
    "### The environment\n",
    "\n",
    "We will use the [LunarLander-v2](https://gymnasium.farama.org/environments/box2d/lunar_lander/) environment from Gymnasium. This environment is a classic rocket trajectory optimization problem. According to Pontryaginâ€™s maximum principle, it is optimal to fire the engine at full throttle or turn it off. This is the reason why this environment has discrete actions: engine on or off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PF46MwbZD00b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video controls autoplay><source src=\"https://huggingface.co/sb3/ppo-LunarLander-v2/resolve/main/replay.mp4\" type=\"video/mp4\"></video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<video controls autoplay><source src=\"https://huggingface.co/sb3/ppo-LunarLander-v2/resolve/main/replay.mp4\" type=\"video/mp4\"></video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on HuggingFace\n",
    "\n",
    "You can easily find the HuggingFace original notebook which uses the [Stable-Baselines3](https://stable-baselines3.readthedocs.io/en/master/). This library provides a set of reliable implementations of reinforcement learning algorithms in PyTorch.\n",
    "\n",
    "The Hugging Face Hub ğŸ¤— works as a central place where anyone can share and explore models and datasets. It has versioning, metrics, visualizations and other features that will allow you to easily collaborate with others.\n",
    "\n",
    "You can see here all the Deep reinforcement Learning models available here https://huggingface.co/models?pipeline_tag=reinforcement-learning&sort=downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jeDAH0h0EBiG"
   },
   "source": [
    "## Install dependencies and create a virtual screen ğŸ”½\n",
    "\n",
    "The first step is to install the dependencies, weâ€™ll install multiple ones.\n",
    "\n",
    "- `gymnasium[box2d]`: Contains the LunarLander-v2 environment\n",
    "- `stable-baselines3[extra]`: The deep reinforcement learning library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yQIGLPDkGhgG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sudo] Passwort fÃ¼r sam: \n"
     ]
    }
   ],
   "source": [
    "!sudo apt install swig cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9XaULfDZDvrC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium[box2d] in /home/sam/anaconda3/envs/pythonProject3/lib/python3.10/site-packages (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/sam/anaconda3/envs/pythonProject3/lib/python3.10/site-packages (from gymnasium[box2d]) (2.1.3)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in /home/sam/anaconda3/envs/pythonProject3/lib/python3.10/site-packages (from gymnasium[box2d]) (1.0.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/sam/anaconda3/envs/pythonProject3/lib/python3.10/site-packages (from gymnasium[box2d]) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/sam/.local/lib/python3.10/site-packages (from gymnasium[box2d]) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/sam/anaconda3/envs/pythonProject3/lib/python3.10/site-packages (from gymnasium[box2d]) (0.0.4)\n",
      "Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n",
      "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pygame==2.1.3 (from gymnasium[box2d])\n",
      "  Downloading pygame-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Collecting swig==4.* (from gymnasium[box2d])\n",
      "  Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.5 kB)\n",
      "Downloading pygame-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: box2d-py\n",
      "  Building wheel for box2d-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=495028 sha256=f7012274e4d0a9934ac3f01a7593f77cb7b81563a8e4496f3373f25a8b88c2ec\n",
      "  Stored in directory: /home/sam/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\n",
      "Successfully built box2d-py\n",
      "Installing collected packages: swig, box2d-py, pygame\n",
      "Successfully installed box2d-py-2.3.5 pygame-2.1.3 swig-4.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium[box2d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stable-baselines3==2.0.0a5\n",
      "  Downloading stable_baselines3-2.0.0a5-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting gymnasium==0.28.1 (from stable-baselines3==2.0.0a5)\n",
      "  Downloading gymnasium-0.28.1-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting numpy (from stable-baselines3==2.0.0a5)\n",
      "  Downloading numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting torch>=1.11 (from stable-baselines3==2.0.0a5)\n",
      "  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting cloudpickle (from stable-baselines3==2.0.0a5)\n",
      "  Downloading cloudpickle-3.1.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting pandas (from stable-baselines3==2.0.0a5)\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting matplotlib (from stable-baselines3==2.0.0a5)\n",
      "  Downloading matplotlib-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting jax-jumpy>=1.0.0 (from gymnasium==0.28.1->stable-baselines3==2.0.0a5)\n",
      "  Downloading jax_jumpy-1.0.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/sam/.local/lib/python3.10/site-packages (from gymnasium==0.28.1->stable-baselines3==2.0.0a5) (4.12.2)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium==0.28.1->stable-baselines3==2.0.0a5)\n",
      "  Using cached Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "Collecting filelock (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting networkx (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
      "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.11->stable-baselines3==2.0.0a5)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->stable-baselines3==2.0.0a5)\n",
      "  Downloading contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->stable-baselines3==2.0.0a5)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->stable-baselines3==2.0.0a5)\n",
      "  Downloading fonttools-4.55.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (164 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->stable-baselines3==2.0.0a5)\n",
      "  Downloading kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/sam/anaconda3/envs/pythonProject3/lib/python3.10/site-packages (from matplotlib->stable-baselines3==2.0.0a5) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib->stable-baselines3==2.0.0a5)\n",
      "  Downloading pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->stable-baselines3==2.0.0a5)\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/sam/.local/lib/python3.10/site-packages (from matplotlib->stable-baselines3==2.0.0a5) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->stable-baselines3==2.0.0a5)\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->stable-baselines3==2.0.0a5)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/sam/anaconda3/envs/pythonProject3/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3==2.0.0a5) (1.16.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11->stable-baselines3==2.0.0a5)\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Downloading stable_baselines3-2.0.0a5-py3-none-any.whl (177 kB)\n",
      "Downloading gymnasium-0.28.1-py3-none-any.whl (925 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m925.5/925.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-3.1.0-py3-none-any.whl (22 kB)\n",
      "Downloading numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (324 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Downloading fonttools-4.55.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\n",
      "Downloading kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: pytz, mpmath, farama-notifications, tzdata, sympy, pyparsing, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, kiwisolver, fsspec, fonttools, filelock, cycler, cloudpickle, triton, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, jax-jumpy, contourpy, nvidia-cusolver-cu12, matplotlib, gymnasium, torch, stable-baselines3\n",
      "Successfully installed MarkupSafe-3.0.2 cloudpickle-3.1.0 contourpy-1.3.1 cycler-0.12.1 farama-notifications-0.0.4 filelock-3.16.1 fonttools-4.55.0 fsspec-2024.10.0 gymnasium-0.28.1 jax-jumpy-1.0.0 jinja2-3.1.4 kiwisolver-1.4.7 matplotlib-3.9.3 mpmath-1.3.0 networkx-3.4.2 numpy-2.1.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 pandas-2.2.3 pillow-11.0.0 pyparsing-3.2.0 pytz-2024.2 stable-baselines3-2.0.0a5 sympy-1.13.1 torch-2.5.1 triton-3.1.0 tzdata-2024.2\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3==2.0.0a5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEKeXQJsQCYm"
   },
   "source": [
    "During the notebook, we'll need to generate a replay video. To do so, with colab, **we need to have a virtual screen to be able to render the environment** (and thus record the frames).\n",
    "\n",
    "Hence the following cell will install virtual screen libraries and create and run a virtual screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j5f2cGkdP-mb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sudo] Passwort fÃ¼r sam: \n",
      "[sudo] Passwort fÃ¼r sam: "
     ]
    }
   ],
   "source": [
    "!sudo apt-get update\n",
    "!sudo apt-get install -y python3-opengl\n",
    "!apt install ffmpeg\n",
    "!apt install xvfb\n",
    "!pip3 install pyvirtualdisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCwBTAwAW9JJ"
   },
   "source": [
    "To make sure the new installed libraries are used, **sometimes it's required to restart the notebook runtime**. The next cell will force the **runtime to crash, so you'll need to connect again and run the code starting from here**. Thanks to this trick, **we will be able to run our virtual screen.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cYvkbef7XEMi"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#import os\n",
    "#os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BE5JWP5rQIKf"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] Das System kann die angegebene Datei nicht finden",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Virtual display\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyvirtualdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Display\n\u001b[1;32m----> 4\u001b[0m virtual_display \u001b[38;5;241m=\u001b[39m \u001b[43mDisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvisible\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m900\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m virtual_display\u001b[38;5;241m.\u001b[39mstart()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyvirtualdisplay\\display.py:54\u001b[0m, in \u001b[0;36mDisplay.__init__\u001b[1;34m(self, backend, visible, size, color_depth, bgcolor, use_xauth, retries, extra_args, manage_global_env, **kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcls\u001b[39m:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown backend: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend)\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_depth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbgcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbgcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_xauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_xauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# check_startup=check_startup,\u001b[39;49;00m\n\u001b[0;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmanage_global_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanage_global_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyvirtualdisplay\\xvfb.py:44\u001b[0m, in \u001b[0;36mXvfbDisplay.__init__\u001b[1;34m(self, size, color_depth, bgcolor, use_xauth, fbdir, dpi, retries, extra_args, manage_global_env)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fbdir \u001b[38;5;241m=\u001b[39m fbdir\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dpi \u001b[38;5;241m=\u001b[39m dpi\n\u001b[1;32m---> 44\u001b[0m \u001b[43mAbstractDisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mPROGRAM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_xauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_xauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmanage_global_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanage_global_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyvirtualdisplay\\abstractdisplay.py:85\u001b[0m, in \u001b[0;36mAbstractDisplay.__init__\u001b[1;34m(self, program, use_xauth, retries, extra_args, manage_global_env)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipe_wfd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retries_current \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 85\u001b[0m helptext \u001b[38;5;241m=\u001b[39m \u001b[43mget_helptext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogram\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_displayfd \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-displayfd\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m helptext\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_displayfd:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyvirtualdisplay\\util.py:13\u001b[0m, in \u001b[0;36mget_helptext\u001b[1;34m(program)\u001b[0m\n\u001b[0;32m      6\u001b[0m cmd \u001b[38;5;241m=\u001b[39m [program, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-help\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# py3.7+\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# p = subprocess.run(cmd, capture_output=True)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# stderr = p.stderr\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# py3.6 also\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m _, stderr \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mcommunicate()\n\u001b[0;32m     21\u001b[0m helptext \u001b[38;5;241m=\u001b[39m stderr\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1022\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[0;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1034\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py:1538\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1538\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1540\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1544\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1545\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1547\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1554\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1555\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Das System kann die angegebene Datei nicht finden"
     ]
    }
   ],
   "source": [
    "# Virtual display\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "virtual_display = Display(visible=0, size=(1400, 900))\n",
    "virtual_display.start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing the virtual display (you have to rerun above code afterwards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virtual display started.\n",
      "Test plot saved as 'test_output.png'.\n",
      "Virtual display stopped.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from pyvirtualdisplay import Display\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "# Start virtual display\n",
    "#display = Display(visible=0, size=(800, 600))\n",
    "#display.start()\n",
    "#print(\"Virtual display started.\")\n",
    "\n",
    "# Create a plot\n",
    "#plt.plot([1, 2, 3], [4, 5, 6])\n",
    "#plt.title(\"Test Plot\")\n",
    "#plt.savefig(\"test_output.png\")\n",
    "#print(\"Test plot saved as 'test_output.png'.\")\n",
    "\n",
    "# Stop the display\n",
    "#display.stop()\n",
    "#print(\"Virtual display stopped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrgpVFqyENVf"
   },
   "source": [
    "## Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cygWLPGsEQ0m"
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.monitor import Monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIrKGGSlENZB"
   },
   "source": [
    "## Create the LunarLander environment and understand how it works\n",
    "\n",
    "### [The environment](https://gymnasium.farama.org/environments/box2d/lunar_lander/)\n",
    "\n",
    "The goal is to train our agent, a [Lunar Lander](https://gymnasium.farama.org/environments/box2d/lunar_lander/), **to land correctly on the moon**. To do that, the agent needs to learn **to adapt its speed and position (horizontal, vertical, and angular) to land correctly.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZNPG0g_UGCfh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____OBSERVATION SPACE_____ \n",
      "\n",
      "Observation Space Shape (8,)\n",
      "Sample observation [ 36.278423   -64.799416     0.8766166    1.9923794   -2.4308565\n",
      "   2.979388     0.36834747   0.8531909 ]\n"
     ]
    }
   ],
   "source": [
    "# We create our environment with gym.make(\"<name_of_the_environment>\")\n",
    "env = gym.make(\"LunarLander-v2\")\n",
    "env.reset()\n",
    "print(\"_____OBSERVATION SPACE_____ \\n\")\n",
    "print(\"Observation Space Shape\", env.observation_space.shape)\n",
    "print(\"Sample observation\", env.observation_space.sample()) # Get a random observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2MXc15qFE0M9"
   },
   "source": [
    "We see with `Observation Space Shape (8,)` that the observation is a vector of size 8, where each value contains different information about the lander:\n",
    "- Horizontal pad coordinate (x)\n",
    "- Vertical pad coordinate (y)\n",
    "- Horizontal speed (x)\n",
    "- Vertical speed (y)\n",
    "- Angle\n",
    "- Angular speed\n",
    "- If the left leg contact point has touched the land (boolean)\n",
    "- If the right leg contact point has touched the land (boolean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "We5WqOBGLoSm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " _____ACTION SPACE_____ \n",
      "\n",
      "Action Space Shape 4\n",
      "Action Space Sample 3\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n _____ACTION SPACE_____ \\n\")\n",
    "print(\"Action Space Shape\", env.action_space.n)\n",
    "print(\"Action Space Sample\", env.action_space.sample()) # Take a random action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyxXwkI2Magx"
   },
   "source": [
    "The action space (the set of possible actions the agent can take) is discrete with 4 actions available:\n",
    "\n",
    "- Action 0: Do nothing,\n",
    "- Action 1: Fire left orientation engine,\n",
    "- Action 2: Fire the main engine,\n",
    "- Action 3: Fire right orientation engine.\n",
    "\n",
    "Reward function (the function that will gives a reward at each timestep):\n",
    "\n",
    "After every step a reward is granted. The total reward of an episode is the **sum of the rewards for all the steps within that episode**.\n",
    "\n",
    "For each step, the reward:\n",
    "\n",
    "- Is increased/decreased the closer/further the lander is to the landing pad.\n",
    "-  Is increased/decreased the slower/faster the lander is moving.\n",
    "- Is decreased the more the lander is tilted (angle not horizontal).\n",
    "- Is increased by 10 points for each leg that is in contact with the ground.\n",
    "- Is decreased by 0.03 points each frame a side engine is firing.\n",
    "- Is decreased by 0.3 points each frame the main engine is firing.\n",
    "\n",
    "The episode receive an **additional reward of -100 or +100 points for crashing or landing safely respectively.**\n",
    "\n",
    "An episode is **considered a solution if it scores at least 200 points.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorized Environment\n",
    "\n",
    "- We create a vectorized environment (a method for stacking multiple independent environments into a single environment) of 16 environments, this way, **we'll have more diverse experiences during the training.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the environment\n",
    "env = make_vec_env('LunarLander-v2', n_envs=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgrE86r5E5IK"
   },
   "source": [
    "## Create the Model\n",
    "\n",
    "Remember the goal: **being able to land the Lunar Lander to the Landing Pad correctly by controlling left, right and main orientation engine**. Based on this, s build the algorithm we're going to use to solve this Problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HV4yiUM_9_Ka"
   },
   "source": [
    "To solve this problem, you're going to implement DQN from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "nxI6hT1GE4-A"
   },
   "outputs": [],
   "source": [
    "#### TODO: Define your DQN agent from scratch!\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining the q network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_size, action_size, hidden_size=64):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = self.relu1(self.fc1(state))\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, buffer_size):\n",
    "        self.memory = deque(maxlen=buffer_size)\n",
    "\n",
    "    def add(self, states, actions, rewards, next_states, dones):\n",
    "        # Store experiences as a batch\n",
    "        for i in range(len(dones)):\n",
    "            experience = (states[i], actions[i], rewards[i], next_states[i], dones[i])\n",
    "            self.memory.append(experience)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        experiences = random.sample(self.memory, batch_size)\n",
    "        return experiences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining the q agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_size,\n",
    "        action_size,\n",
    "        buffer_size=100000,\n",
    "        batch_size=64,\n",
    "        gamma=0.99,\n",
    "        lr=1e-3,\n",
    "        tau=1e-3,\n",
    "        update_every=4,\n",
    "        device=\"cpu\",\n",
    "    ):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.device = torch.device(device)\n",
    "\n",
    "        # Q-Network\n",
    "        self.qnetwork_local = QNetwork(state_size, action_size).to(self.device)\n",
    "        self.qnetwork_target = QNetwork(state_size, action_size).to(self.device)\n",
    "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=lr)\n",
    "\n",
    "        # Replay memory\n",
    "        self.memory = ReplayBuffer(buffer_size)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Hyperparameters\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.update_every = update_every\n",
    "\n",
    "        # Initialize time step for updating every update_every steps\n",
    "        self.t_step = 0\n",
    "\n",
    "    def step(self, states, actions, rewards, next_states, dones):\n",
    "        # Store experiences in replay memory\n",
    "        self.memory.add(states, actions, rewards, next_states, dones)\n",
    "\n",
    "        # Learn every update_every time steps\n",
    "        self.t_step = (self.t_step + 1) % self.update_every\n",
    "        if self.t_step == 0:\n",
    "            if len(self.memory) > self.batch_size:\n",
    "                experiences = self.memory.sample(self.batch_size)\n",
    "                self.learn(experiences)\n",
    "\n",
    "    def act(self, states, eps=0.0):\n",
    "        # states is a batch of states (n_envs x state_size)\n",
    "        states = torch.from_numpy(states).float().to(self.device)\n",
    "        self.qnetwork_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.qnetwork_local(states)\n",
    "        self.qnetwork_local.train()\n",
    "        # Epsilon-greedy action selection\n",
    "        action_values = action_values.cpu().data.numpy()\n",
    "        batch_size = states.shape[0]\n",
    "        best_actions = np.argmax(action_values, axis=1)\n",
    "        random_actions = np.random.randint(self.action_size, size=batch_size)\n",
    "        eps_mask = np.random.rand(batch_size) < eps\n",
    "        actions = np.where(eps_mask, random_actions, best_actions)\n",
    "        return actions\n",
    "\n",
    "    def learn(self, experiences):\n",
    "        states, actions, rewards, next_states, dones = zip(*experiences)\n",
    "\n",
    "        # Convert to tensors\n",
    "        states = torch.from_numpy(np.vstack(states)).float().to(self.device)\n",
    "        actions = torch.from_numpy(np.vstack(actions)).long().to(self.device)\n",
    "        rewards = torch.from_numpy(np.vstack(rewards)).float().to(self.device)\n",
    "        next_states = torch.from_numpy(np.vstack(next_states)).float().to(self.device)\n",
    "        dones = (\n",
    "            torch.from_numpy(np.vstack(dones).astype(np.uint8)).float().to(self.device)\n",
    "        )\n",
    "\n",
    "        # Get max predicted Q values (for next states) from target model\n",
    "        Q_targets_next = (\n",
    "            self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "        )\n",
    "        # Compute Q targets for current states\n",
    "        Q_targets = rewards + (self.gamma * Q_targets_next * (1 - dones))\n",
    "\n",
    "        # Get expected Q values from local model\n",
    "        Q_expected = self.qnetwork_local(states).gather(1, actions)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = nn.MSELoss()(Q_expected, Q_targets)\n",
    "\n",
    "        # Minimize the loss\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Soft update target network parameters\n",
    "        self.soft_update(self.qnetwork_local, self.qnetwork_target)\n",
    "\n",
    "    def soft_update(self, local_model, target_model):\n",
    "        # Î¸_target = Ï„*Î¸_local + (1 - Ï„)*Î¸_target\n",
    "        for target_param, local_param in zip(\n",
    "            target_model.parameters(), local_model.parameters()\n",
    "        ):\n",
    "            target_param.data.copy_(\n",
    "                self.tau * local_param.data + (1.0 - self.tau) * target_param.data\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setting up the enviroment again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "\n",
    "agent = DQNAgent(\n",
    "    state_size, action_size, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClJJk88yoBUi"
   },
   "source": [
    "## Train the DQN agent\n",
    "- Let's train our agent for 1,000,000 timesteps, don't forget to use GPU (on your local installation, Google Colab or similar). You will notice that experiments will take considerably longer than previous labs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bQzQ-QcE3zo"
   },
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "poBCy9u_csyR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "def dqn(n_episodes=2000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    scores = []  # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start  # initialize epsilon\n",
    "    timestep_count = 0  # total number of timesteps\n",
    "\n",
    "    # Initialize states and scores for each environment\n",
    "    states = env.reset()\n",
    "    n_envs = env.num_envs\n",
    "    env_scores = np.zeros(n_envs)\n",
    "    print(f\"Number of environments: {n_envs}\")\n",
    "\n",
    "    for i_episode in range(1, n_episodes + 1):\n",
    "        episode_scores = []\n",
    "\n",
    "        for t in range(max_t):\n",
    "            actions = agent.act(states, eps)\n",
    "            next_states, rewards, dones, infos = env.step(actions)\n",
    "\n",
    "            agent.step(states, actions, rewards, next_states, dones)\n",
    "\n",
    "            env_scores += rewards\n",
    "            timestep_count += n_envs/16\n",
    "            #print(f\"Episode {i_episode}, Timesteps: {timestep_count}\")\n",
    "\n",
    "            # Collect scores and reset env_scores for done environments\n",
    "            for i, done in enumerate(dones):\n",
    "                if done:\n",
    "                    episode_scores.append(env_scores[i])\n",
    "                    env_scores[i] = 0.0  # Reset the score for the environment\n",
    "\n",
    "            states = next_states\n",
    "\n",
    "            if timestep_count >= 1_000_000:\n",
    "                print(f\"Reached {timestep_count} timesteps. Training complete.\")\n",
    "                return scores\n",
    "\n",
    "        # Update epsilon\n",
    "        eps = max(eps_end, eps_decay * eps)\n",
    "\n",
    "        # Record the scores\n",
    "        if len(episode_scores) > 0:\n",
    "            avg_score = np.mean(episode_scores)\n",
    "            scores_window.append(avg_score)\n",
    "            scores.append(avg_score)\n",
    "\n",
    "            if i_episode % 10 == 0:\n",
    "                print(\n",
    "                    f\"Episode {i_episode}\\tAverage Score: {np.mean(scores_window):.2f}\"\n",
    "                )\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "#scores = dqn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotubg tge dqn learning scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m----> 4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(\u001b[43mscores\u001b[49m)), scores)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpisode #\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scores' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.xlabel(\"Episode #\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"DQN Agent Performance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "savinf the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(agent.qnetwork_local.state_dict(), \"dqn_lunarlander.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BY_HuedOoISR"
   },
   "source": [
    "## Evaluate the agent\n",
    "- Now that our Lunar Lander agent is trained, we need to **check its performance**.\n",
    "\n",
    "**Note**: When you evaluate your agent, you should not use your training environment but create an evaluation environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "yRpno0glsADy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flras\\AppData\\Local\\Temp\\ipykernel_21192\\2620854751.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  agent.qnetwork_local.load_state_dict(torch.load(\"dqn_lunarlander_best.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reward: -737.59 +/- 359.53\n"
     ]
    }
   ],
   "source": [
    "# Create a new environment for evaluation\n",
    "eval_env = gym.make(\"LunarLander-v2\")\n",
    "\n",
    "# Load the trained model\n",
    "agent.qnetwork_local.load_state_dict(torch.load(\"dqn_lunarlander_best.pth\"))\n",
    "\n",
    "\n",
    "# Function to evaluate the trained agent\n",
    "# dont run this in between above and optuna code since this will reset enviroment \n",
    "# def evaluate_agent(env, agent, n_episodes=10):\n",
    "def evaluate_agent(env, agent, n_episodes=10):\n",
    "    total_rewards = []\n",
    "    for episode in range(n_episodes):\n",
    "        state, _ = env.reset()  # Extract the state from the reset output\n",
    "        episode_reward = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            # Convert state to tensor and pass it to the model\n",
    "            state_tensor = torch.from_numpy(state).float().unsqueeze(0).to(agent.device)\n",
    "            with torch.no_grad():\n",
    "                action = np.argmax(agent.qnetwork_local(state_tensor).cpu().data.numpy())\n",
    "            step_result = env.step(action)\n",
    "\n",
    "            # Unpack step_result dynamically based on its length\n",
    "            if len(step_result) == 4:\n",
    "                next_state, reward, done, _ = step_result\n",
    "            elif len(step_result) == 5:\n",
    "                next_state, reward, done, _, _ = step_result\n",
    "\n",
    "            episode_reward += reward\n",
    "            state = next_state  # Update state for the next step\n",
    "        total_rewards.append(episode_reward)\n",
    "    return np.mean(total_rewards), np.std(total_rewards)\n",
    "\n",
    "# Evaluate the model\n",
    "n_episodes = 10  # Define the number of episodes for evaluation\n",
    "mean_reward, std_reward = evaluate_agent(eval_env, agent)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Mean Reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we implement hyperparameter tuning using optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flras\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gym\\wrappers\\record_video.py:75: UserWarning: \u001b[33mWARN: Overwriting existing videos at c:\\Users\\flras\\Documents\\ZHAW\\rl_lunar_landing\\evaluation_videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\flras\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gym\\wrappers\\monitoring\\video_recorder.py:59: UserWarning: \u001b[33mWARN: Disabling video recorder because environment <TimeLimit<OrderEnforcing<PassiveEnvChecker<LunarLander<LunarLander-v2>>>>> was not initialized with any compatible video mode between `rgb_array` and `rgb_array_list`\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\flras\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gym\\envs\\box2d\\lunar_lander.py:604: UserWarning: \u001b[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym(\"LunarLander-v2\", render_mode=\"rgb_array\")\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'bool8'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m eval_env \u001b[38;5;241m=\u001b[39m RecordVideo(eval_env, video_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation_videos\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Evaluate the agent and record a video\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[43mevaluate_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_agent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m eval_env\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Find the recorded video file\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[20], line 22\u001b[0m, in \u001b[0;36mevaluate_agent\u001b[1;34m(env, agent, n_episodes)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     21\u001b[0m     action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(agent\u001b[38;5;241m.\u001b[39mqnetwork_local(state_tensor)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m---> 22\u001b[0m step_result \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Unpack step_result dynamically based on its length\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(step_result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gym\\wrappers\\record_video.py:142\u001b[0m, in \u001b[0;36mRecordVideo.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m    135\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment using action, recording observations if :attr:`self.recording`.\"\"\"\u001b[39;00m\n\u001b[0;32m    136\u001b[0m     (\n\u001b[0;32m    137\u001b[0m         observations,\n\u001b[0;32m    138\u001b[0m         rewards,\n\u001b[0;32m    139\u001b[0m         terminateds,\n\u001b[0;32m    140\u001b[0m         truncateds,\n\u001b[0;32m    141\u001b[0m         infos,\n\u001b[1;32m--> 142\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterminated \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtruncated):\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;66;03m# increment steps and episodes\u001b[39;00m\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_id \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gym\\wrappers\\time_limit.py:50\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m     40\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gym\\wrappers\\order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gym\\wrappers\\env_checker.py:37\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menv_step_passive_checker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gym\\utils\\passive_env_checker.py:233\u001b[0m, in \u001b[0;36menv_step_passive_checker\u001b[1;34m(env, action)\u001b[0m\n\u001b[0;32m    230\u001b[0m obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# np.bool is actual python bool not np boolean type, therefore bool_ or bool8\u001b[39;00m\n\u001b[1;32m--> 233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(terminated, (\u001b[38;5;28mbool\u001b[39m, \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbool8\u001b[49m)):\n\u001b[0;32m    234\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpects `terminated` signal to be a boolean, actual type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(terminated)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    236\u001b[0m     )\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncated, (\u001b[38;5;28mbool\u001b[39m, np\u001b[38;5;241m.\u001b[39mbool8)):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\__init__.py:428\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchar\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mchar\u001b[39;00m\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m char\u001b[38;5;241m.\u001b[39mchararray\n\u001b[1;32m--> 428\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    429\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'bool8'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "from gym.wrappers import RecordVideo\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "import glob\n",
    "\n",
    "# Reinitialize and wrap the evaluation environment for recording\n",
    "eval_env = gym.make(\"LunarLander-v2\")\n",
    "eval_env = RecordVideo(eval_env, video_folder=\"evaluation_videos\")\n",
    "\n",
    "# Evaluate the agent and record a video\n",
    "evaluate_agent(eval_env, best_agent, n_episodes=1)\n",
    "eval_env.close()\n",
    "\n",
    "# Find the recorded video file\n",
    "video_files = glob.glob(\"evaluation_videos/openaigym.video.*.mp4\")\n",
    "if len(video_files) > 0:\n",
    "    video_path = video_files[0]  # Take the first video file\n",
    "    with io.open(video_path, \"r+b\") as file:\n",
    "        video = file.read()\n",
    "    encoded_video = base64.b64encode(video).decode(\"ascii\")\n",
    "    display(HTML(f'<video width=\"640\" height=\"480\" controls>'\n",
    "                 f'<source src=\"data:video/mp4;base64,{encoded_video}\" type=\"video/mp4\">'\n",
    "                 f'</video>'))\n",
    "else:\n",
    "    print(\"No video found in 'evaluation_videos/' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting moviepy\n",
      "  Downloading moviepy-2.1.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: decorator<6.0,>=4.0.2 in c:\\users\\flras\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from moviepy) (5.1.1)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\flras\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from moviepy) (2.36.0)\n",
      "Collecting imageio_ffmpeg>=0.2.0 (from moviepy)\n",
      "  Downloading imageio_ffmpeg-0.5.1-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: numpy>=1.25.0 in c:\\users\\flras\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from moviepy) (2.1.2)\n",
      "Collecting proglog<=1.0.0 (from moviepy)\n",
      "  Downloading proglog-0.1.10-py3-none-any.whl.metadata (639 bytes)\n",
      "Collecting python-dotenv>=0.10 (from moviepy)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting pillow<11.0,>=9.2.0 (from moviepy)\n",
      "  Downloading pillow-10.4.0-cp311-cp311-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from imageio_ffmpeg>=0.2.0->moviepy) (65.5.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\flras\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from proglog<=1.0.0->moviepy) (4.66.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\flras\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->proglog<=1.0.0->moviepy) (0.4.6)\n",
      "Downloading moviepy-2.1.1-py3-none-any.whl (123 kB)\n",
      "Downloading imageio_ffmpeg-0.5.1-py3-none-win_amd64.whl (22.6 MB)\n",
      "   ---------------------------------------- 0.0/22.6 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 8.4/22.6 MB 43.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 18.9/22.6 MB 47.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 22.6/22.6 MB 43.3 MB/s eta 0:00:00\n",
      "Downloading pillow-10.4.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.6/2.6 MB 48.8 MB/s eta 0:00:00\n",
      "Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv, pillow, imageio_ffmpeg, proglog, moviepy\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 11.0.0\n",
      "    Uninstalling pillow-11.0.0:\n",
      "      Successfully uninstalled pillow-11.0.0\n",
      "Successfully installed imageio_ffmpeg-0.5.1 moviepy-2.1.1 pillow-10.4.0 proglog-0.1.10 python-dotenv-1.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\flras\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\~il'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-04 22:53:53,732] A new study created in memory with name: no-name-4684f81a-aa69-42dd-97e1-e82632e62d62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flras\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\optuna\\distributions.py:689: UserWarning: The distribution is specified by [0.8, 0.999] and step=0.01, but the range is not divisible by `step`. It will be replaced by [0.8, 0.99].\n",
      "  warnings.warn(\n",
      "C:\\Users\\flras\\AppData\\Local\\Temp\\ipykernel_25368\\1044926565.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
      "C:\\Users\\flras\\AppData\\Local\\Temp\\ipykernel_25368\\1044926565.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  tau = trial.suggest_loguniform(\"tau\", 1e-4, 1e-2)\n",
      "[I 2024-12-04 23:04:16,393] Trial 0 finished with value: 98.17068863442732 and parameters: {'buffer_size': 100149, 'batch_size': 128, 'gamma': 0.81, 'lr': 0.0004419046202024982, 'tau': 0.00045153204344744935, 'update_every': 20}. Best is trial 0 with value: 98.17068863442732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-04 23:18:52,100] Trial 1 finished with value: 153.52757266908912 and parameters: {'buffer_size': 99609, 'batch_size': 96, 'gamma': 0.91, 'lr': 2.4602916346467126e-05, 'tau': 0.004604649528448072, 'update_every': 3}. Best is trial 0 with value: 98.17068863442732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-04 23:45:25,872] Trial 2 finished with value: 33.95351371021198 and parameters: {'buffer_size': 29485, 'batch_size': 256, 'gamma': 0.9400000000000001, 'lr': 5.2500540619291205e-05, 'tau': 0.00023870143460263957, 'update_every': 1}. Best is trial 2 with value: 33.95351371021198.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-04 23:55:41,573] Trial 3 finished with value: 167.46114652873902 and parameters: {'buffer_size': 125692, 'batch_size': 128, 'gamma': 0.9700000000000001, 'lr': 7.013503259927002e-05, 'tau': 0.0015717796998587362, 'update_every': 20}. Best is trial 2 with value: 33.95351371021198.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 00:04:59,846] Trial 4 finished with value: 182.00585130134343 and parameters: {'buffer_size': 219938, 'batch_size': 96, 'gamma': 0.8700000000000001, 'lr': 1.7183166251957386e-05, 'tau': 0.001341759037791698, 'update_every': 9}. Best is trial 2 with value: 33.95351371021198.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 00:21:51,163] Trial 5 finished with value: 3.6575458161964773 and parameters: {'buffer_size': 112945, 'batch_size': 192, 'gamma': 0.9500000000000001, 'lr': 0.000976800359579602, 'tau': 0.0081970090395435, 'update_every': 4}. Best is trial 5 with value: 3.6575458161964773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 00:40:46,243] Trial 6 finished with value: 44.73919604497978 and parameters: {'buffer_size': 286722, 'batch_size': 160, 'gamma': 0.8200000000000001, 'lr': 0.0005736748492595513, 'tau': 0.0009752671625189889, 'update_every': 2}. Best is trial 5 with value: 3.6575458161964773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 00:51:36,213] Trial 7 finished with value: 190.95709643893076 and parameters: {'buffer_size': 652892, 'batch_size': 96, 'gamma': 0.8400000000000001, 'lr': 5.047580610214511e-05, 'tau': 0.0012068589629550426, 'update_every': 9}. Best is trial 5 with value: 3.6575458161964773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 01:01:40,203] Trial 8 finished with value: 180.48851403807998 and parameters: {'buffer_size': 214888, 'batch_size': 256, 'gamma': 0.93, 'lr': 3.374352943309717e-05, 'tau': 0.008265519857446384, 'update_every': 16}. Best is trial 5 with value: 3.6575458161964773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 01:11:31,196] Trial 9 finished with value: 100.5057050398892 and parameters: {'buffer_size': 262041, 'batch_size': 128, 'gamma': 0.91, 'lr': 0.0009197262535202209, 'tau': 0.00014123432343530158, 'update_every': 16}. Best is trial 5 with value: 3.6575458161964773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 01:27:18,145] Trial 10 finished with value: 14.176903105558104 and parameters: {'buffer_size': 11594, 'batch_size': 192, 'gamma': 0.99, 'lr': 0.00018668071327646268, 'tau': 0.0035046065818641523, 'update_every': 5}. Best is trial 5 with value: 3.6575458161964773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 01:42:33,689] Trial 11 finished with value: 10.344758040002073 and parameters: {'buffer_size': 14941, 'batch_size': 192, 'gamma': 0.98, 'lr': 0.0001910107490348443, 'tau': 0.003954041331466457, 'update_every': 6}. Best is trial 5 with value: 3.6575458161964773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 01:57:14,792] Trial 12 finished with value: 28.914007563809374 and parameters: {'buffer_size': 41666, 'batch_size': 192, 'gamma': 0.9600000000000001, 'lr': 0.00018902225289218084, 'tau': 0.008810514101194744, 'update_every': 6}. Best is trial 5 with value: 3.6575458161964773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 02:13:23,828] Trial 13 finished with value: 45.34841200509256 and parameters: {'buffer_size': 10747, 'batch_size': 32, 'gamma': 0.99, 'lr': 0.00016772692605790466, 'tau': 0.003227625776202138, 'update_every': 6}. Best is trial 5 with value: 3.6575458161964773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 02:30:00,477] Trial 14 finished with value: 9.172169204697123 and parameters: {'buffer_size': 35254, 'batch_size': 224, 'gamma': 0.9500000000000001, 'lr': 0.0003664841173733219, 'tau': 0.0052618162240529965, 'update_every': 10}. Best is trial 5 with value: 3.6575458161964773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 02:43:29,437] Trial 15 finished with value: 48.95019673306358 and parameters: {'buffer_size': 44960, 'batch_size': 224, 'gamma': 0.8700000000000001, 'lr': 0.0004415084693575735, 'tau': 0.00933827556205823, 'update_every': 12}. Best is trial 5 with value: 3.6575458161964773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 02:59:07,461] Trial 16 finished with value: 32.66224028397933 and parameters: {'buffer_size': 24267, 'batch_size': 224, 'gamma': 0.9400000000000001, 'lr': 0.0008812776378215722, 'tau': 0.002133103910942917, 'update_every': 12}. Best is trial 5 with value: 3.6575458161964773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 03:12:24,549] Trial 17 finished with value: 49.188559032016954 and parameters: {'buffer_size': 61299, 'batch_size': 224, 'gamma': 0.9500000000000001, 'lr': 0.00033923946366947735, 'tau': 0.0006628532527641044, 'update_every': 9}. Best is trial 5 with value: 3.6575458161964773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 03:25:55,250] Trial 18 finished with value: 53.38642462186245 and parameters: {'buffer_size': 960448, 'batch_size': 160, 'gamma': 0.89, 'lr': 0.0003173900814123301, 'tau': 0.00546180749532601, 'update_every': 15}. Best is trial 5 with value: 3.6575458161964773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 03:42:19,191] Trial 19 finished with value: 18.384602983825562 and parameters: {'buffer_size': 71257, 'batch_size': 256, 'gamma': 0.91, 'lr': 0.0009670587517813555, 'tau': 0.002530037956923264, 'update_every': 4}. Best is trial 5 with value: 3.6575458161964773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 03:50:43,409] Trial 20 finished with value: 149.96871431501705 and parameters: {'buffer_size': 22178, 'batch_size': 32, 'gamma': 0.93, 'lr': 0.00011551513070333827, 'tau': 0.005919558351574953, 'update_every': 13}. Best is trial 5 with value: 3.6575458161964773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 04:07:01,976] Trial 21 finished with value: 6.459219320565163 and parameters: {'buffer_size': 17059, 'batch_size': 192, 'gamma': 0.9700000000000001, 'lr': 0.0002686516292530059, 'tau': 0.005516013483187172, 'update_every': 7}. Best is trial 5 with value: 3.6575458161964773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 04:23:41,414] Trial 22 finished with value: 2.813244138181283 and parameters: {'buffer_size': 16680, 'batch_size': 192, 'gamma': 0.9600000000000001, 'lr': 0.000549556644379358, 'tau': 0.00634586763373831, 'update_every': 8}. Best is trial 22 with value: 2.813244138181283.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 04:38:37,597] Trial 23 finished with value: -0.20478604074843554 and parameters: {'buffer_size': 16868, 'batch_size': 192, 'gamma': 0.9700000000000001, 'lr': 0.000600049363806618, 'tau': 0.009799043697640125, 'update_every': 8}. Best is trial 23 with value: -0.20478604074843554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 04:53:30,051] Trial 24 finished with value: 12.933901257087998 and parameters: {'buffer_size': 134970, 'batch_size': 160, 'gamma': 0.9700000000000001, 'lr': 0.0006201920208604126, 'tau': 0.009495191161074926, 'update_every': 8}. Best is trial 23 with value: -0.20478604074843554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 05:10:06,172] Trial 25 finished with value: 9.415236396516034 and parameters: {'buffer_size': 16475, 'batch_size': 192, 'gamma': 0.9600000000000001, 'lr': 0.0006528054860445365, 'tau': 0.007001406552050815, 'update_every': 4}. Best is trial 23 with value: -0.20478604074843554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 05:25:41,765] Trial 26 finished with value: 35.43191459922584 and parameters: {'buffer_size': 58754, 'batch_size': 160, 'gamma': 0.92, 'lr': 0.0005549863483350506, 'tau': 0.002510983386765341, 'update_every': 7}. Best is trial 23 with value: -0.20478604074843554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 05:38:27,210] Trial 27 finished with value: 51.69098524407839 and parameters: {'buffer_size': 21663, 'batch_size': 224, 'gamma': 0.89, 'lr': 0.0007124741949716989, 'tau': 0.007153690003123542, 'update_every': 11}. Best is trial 23 with value: -0.20478604074843554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 06:03:01,612] Trial 28 finished with value: 94.34815149599787 and parameters: {'buffer_size': 425300, 'batch_size': 192, 'gamma': 0.99, 'lr': 1.1785959957766359e-05, 'tau': 0.003280448600408245, 'update_every': 1}. Best is trial 23 with value: -0.20478604074843554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 06:13:19,404] Trial 29 finished with value: 86.32557122237715 and parameters: {'buffer_size': 79898, 'batch_size': 128, 'gamma': 0.8, 'lr': 0.000445946024943172, 'tau': 0.0005894287178906368, 'update_every': 14}. Best is trial 23 with value: -0.20478604074843554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 06:32:00,663] Trial 30 finished with value: 26.632155174694557 and parameters: {'buffer_size': 136362, 'batch_size': 160, 'gamma': 0.9500000000000001, 'lr': 0.0002633913563712715, 'tau': 0.0019226299975672533, 'update_every': 4}. Best is trial 23 with value: -0.20478604074843554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 06:46:49,565] Trial 31 finished with value: 7.660981320342072 and parameters: {'buffer_size': 14880, 'batch_size': 192, 'gamma': 0.9700000000000001, 'lr': 0.00024142218631241486, 'tau': 0.006294380132852643, 'update_every': 7}. Best is trial 23 with value: -0.20478604074843554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 07:02:56,864] Trial 32 finished with value: 13.239625777250502 and parameters: {'buffer_size': 30972, 'batch_size': 192, 'gamma': 0.98, 'lr': 0.0004844281961174817, 'tau': 0.004523332576281541, 'update_every': 8}. Best is trial 23 with value: -0.20478604074843554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 07:19:09,136] Trial 33 finished with value: 6.9413796590364925 and parameters: {'buffer_size': 21704, 'batch_size': 224, 'gamma': 0.9600000000000001, 'lr': 0.000760444423894317, 'tau': 0.009799325248136766, 'update_every': 5}. Best is trial 23 with value: -0.20478604074843554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 07:36:26,244] Trial 34 finished with value: 9.926906957062453 and parameters: {'buffer_size': 101070, 'batch_size': 160, 'gamma': 0.9400000000000001, 'lr': 0.000393579082174519, 'tau': 0.004590673822230569, 'update_every': 3}. Best is trial 23 with value: -0.20478604074843554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 07:51:08,309] Trial 35 finished with value: 31.465079500655225 and parameters: {'buffer_size': 14870, 'batch_size': 256, 'gamma': 0.98, 'lr': 0.00012623779275103188, 'tau': 0.007164238686367908, 'update_every': 10}. Best is trial 23 with value: -0.20478604074843554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 08:03:45,805] Trial 36 finished with value: 74.71537008026155 and parameters: {'buffer_size': 10536, 'batch_size': 192, 'gamma': 0.9700000000000001, 'lr': 0.00030596624695852445, 'tau': 0.00023531130728183887, 'update_every': 8}. Best is trial 23 with value: -0.20478604074843554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 08:15:43,839] Trial 37 finished with value: 149.57667271500094 and parameters: {'buffer_size': 42095, 'batch_size': 96, 'gamma': 0.93, 'lr': 7.270477321460756e-05, 'tau': 0.005043853061864419, 'update_every': 7}. Best is trial 23 with value: -0.20478604074843554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 08:26:43,507] Trial 38 finished with value: 63.558595256949545 and parameters: {'buffer_size': 174927, 'batch_size': 128, 'gamma': 0.8700000000000001, 'lr': 0.0005185332724792112, 'tau': 0.002698148746624238, 'update_every': 20}. Best is trial 23 with value: -0.20478604074843554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 08:45:49,016] Trial 39 finished with value: 1.098316231851691 and parameters: {'buffer_size': 18608, 'batch_size': 224, 'gamma': 0.9500000000000001, 'lr': 0.0007447927361715593, 'tau': 0.0009095469431936578, 'update_every': 2}. Best is trial 23 with value: -0.20478604074843554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 09:03:59,678] Trial 40 finished with value: 14.743772459025177 and parameters: {'buffer_size': 25699, 'batch_size': 256, 'gamma': 0.91, 'lr': 0.0007847850171039565, 'tau': 0.0009547527755293457, 'update_every': 2}. Best is trial 23 with value: -0.20478604074843554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 09:23:44,952] Trial 41 finished with value: -1.8317190562885535 and parameters: {'buffer_size': 18436, 'batch_size': 224, 'gamma': 0.9600000000000001, 'lr': 0.0006077987347236953, 'tau': 0.0006854824921098284, 'update_every': 2}. Best is trial 41 with value: -1.8317190562885535.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 09:48:35,429] Trial 42 finished with value: -0.03643413077838836 and parameters: {'buffer_size': 18621, 'batch_size': 224, 'gamma': 0.9400000000000001, 'lr': 0.0009664052089932806, 'tau': 0.00036421982701256346, 'update_every': 1}. Best is trial 41 with value: -1.8317190562885535.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 10:14:16,421] Trial 43 finished with value: -3.679877318604797 and parameters: {'buffer_size': 12964, 'batch_size': 224, 'gamma': 0.9400000000000001, 'lr': 0.000535187060380567, 'tau': 0.00034542585077031835, 'update_every': 1}. Best is trial 43 with value: -3.679877318604797.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 10:38:17,301] Trial 44 finished with value: 6.461528604368795 and parameters: {'buffer_size': 13716, 'batch_size': 224, 'gamma': 0.92, 'lr': 0.000716415750229016, 'tau': 0.0003211347365320807, 'update_every': 1}. Best is trial 43 with value: -3.679877318604797.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 10:57:32,029] Trial 45 finished with value: 5.003476951594812 and parameters: {'buffer_size': 20192, 'batch_size': 256, 'gamma': 0.9400000000000001, 'lr': 0.0009948728670570869, 'tau': 0.0003986041867649172, 'update_every': 2}. Best is trial 43 with value: -3.679877318604797.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 11:15:06,399] Trial 46 finished with value: -4.583910255420829 and parameters: {'buffer_size': 12728, 'batch_size': 224, 'gamma': 0.9500000000000001, 'lr': 0.0006304159219839015, 'tau': 0.0007586575243168811, 'update_every': 3}. Best is trial 46 with value: -4.583910255420829.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 11:28:11,092] Trial 47 finished with value: 109.22386626075814 and parameters: {'buffer_size': 12635, 'batch_size': 256, 'gamma': 0.93, 'lr': 2.5071898939369616e-05, 'tau': 0.00023528554297233588, 'update_every': 3}. Best is trial 46 with value: -4.583910255420829.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 11:36:21,517] Trial 48 finished with value: 103.86632708349754 and parameters: {'buffer_size': 10017, 'batch_size': 224, 'gamma': 0.92, 'lr': 0.00041595820012569154, 'tau': 0.00015953507080461682, 'update_every': 18}. Best is trial 46 with value: -4.583910255420829.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Q-Network is on device: cuda:0\n",
      "Target Q-Network is on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 12:00:18,018] Trial 49 finished with value: -0.4940403243009719 and parameters: {'buffer_size': 28711, 'batch_size': 224, 'gamma': 0.9400000000000001, 'lr': 0.0006139087889162359, 'tau': 0.0005101704384507866, 'update_every': 1}. Best is trial 46 with value: -4.583910255420829.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'buffer_size': 12728, 'batch_size': 224, 'gamma': 0.9500000000000001, 'lr': 0.0006304159219839015, 'tau': 0.0007586575243168811, 'update_every': 3}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "from optuna.visualization import (\n",
    "    plot_optimization_history,\n",
    "    plot_param_importances,\n",
    "    plot_parallel_coordinate,\n",
    "    plot_slice,\n",
    ")\n",
    "print(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to be tuned\n",
    "    buffer_size = trial.suggest_int(\"buffer_size\", 10000, 1000000, log=True)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 32, 256, step=32)\n",
    "    gamma = trial.suggest_float(\"gamma\", 0.8, 0.999, step=0.01)\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
    "    tau = trial.suggest_loguniform(\"tau\", 1e-4, 1e-2)\n",
    "    update_every = trial.suggest_int(\"update_every\", 1, 20)\n",
    "\n",
    "    # Initialize the agent with trial hyperparameters\n",
    "    agent = DQNAgent(\n",
    "        state_size=env.observation_space.shape[0],\n",
    "        action_size=env.action_space.n,\n",
    "        buffer_size=buffer_size,\n",
    "        batch_size=batch_size,\n",
    "        gamma=gamma,\n",
    "        lr=lr,\n",
    "        tau=tau,\n",
    "        update_every=update_every,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    )\n",
    "    print(\"Local Q-Network is on device:\", next(agent.qnetwork_local.parameters()).device)\n",
    "    print(\"Target Q-Network is on device:\", next(agent.qnetwork_target.parameters()).device)\n",
    "\n",
    "\n",
    "    def dqn_for_optuna(n_episodes=200, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "        scores_window = deque(maxlen=100)  # last 100 scores\n",
    "        eps = eps_start  # initialize epsilon\n",
    "        states = env.reset()\n",
    "        n_envs = env.num_envs\n",
    "        env_scores = np.zeros(n_envs)\n",
    "\n",
    "        for i_episode in range(1, n_episodes + 1):\n",
    "            episode_scores = []\n",
    "            for t in range(max_t):\n",
    "                actions = agent.act(states, eps)\n",
    "                next_states, rewards, dones, infos = env.step(actions)\n",
    "\n",
    "                agent.step(states, actions, rewards, next_states, dones)\n",
    "\n",
    "                env_scores += rewards\n",
    "                for i, done in enumerate(dones):\n",
    "                    if done:\n",
    "                        episode_scores.append(env_scores[i])\n",
    "                        env_scores[i] = 0.0  # Reset the score for the environment\n",
    "\n",
    "                states = next_states\n",
    "\n",
    "            # Update epsilon\n",
    "            eps = max(eps_end, eps_decay * eps)\n",
    "\n",
    "            # Record scores\n",
    "            if len(episode_scores) > 0:\n",
    "                avg_score = np.mean(episode_scores)\n",
    "                scores_window.append(avg_score)\n",
    "\n",
    "            # Early stopping if average score is good enough\n",
    "            if len(scores_window) == 100 and np.mean(scores_window) >= 200:\n",
    "                break\n",
    "\n",
    "        return np.mean(scores_window)\n",
    "\n",
    "    # Run the DQN training with the current hyperparameters\n",
    "    avg_score = dqn_for_optuna()\n",
    "\n",
    "    # Optuna maximizes the objective, so we negate the score for minimization\n",
    "    return -avg_score\n",
    "\n",
    "\n",
    "# Create Optuna study\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters: \", study.best_params)\n",
    "\n",
    "# Save the study results for further analysis\n",
    "study_df = study.trials_dataframe()\n",
    "study_df.to_csv(\"optuna_dqn_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show optim history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optuna.visualization.plot_optimization_history(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "cliponaxis": false,
         "hovertemplate": [
          "buffer_size (IntDistribution): 0.004853785125694006<extra></extra>",
          "tau (FloatDistribution): 0.023091842714308412<extra></extra>",
          "gamma (FloatDistribution): 0.045467443087045166<extra></extra>",
          "batch_size (IntDistribution): 0.16313188797131073<extra></extra>",
          "update_every (IntDistribution): 0.1770052562701235<extra></extra>",
          "lr (FloatDistribution): 0.5864497848315181<extra></extra>"
         ],
         "name": "Objective Value",
         "orientation": "h",
         "text": [
          "<0.01",
          "0.02",
          "0.05",
          "0.16",
          "0.18",
          "0.59"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          0.004853785125694006,
          0.023091842714308412,
          0.045467443087045166,
          0.16313188797131073,
          0.1770052562701235,
          0.5864497848315181
         ],
         "y": [
          "buffer_size",
          "tau",
          "gamma",
          "batch_size",
          "update_every",
          "lr"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Hyperparameter Importances"
        },
        "xaxis": {
         "title": {
          "text": "Hyperparameter Importance"
         }
        },
        "yaxis": {
         "title": {
          "text": "Hyperparameter"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of environments: 16\n",
      "Episode 10\tAverage Score: -165.50\n",
      "Episode 20\tAverage Score: -151.88\n",
      "Episode 30\tAverage Score: -139.35\n",
      "Episode 40\tAverage Score: -130.64\n",
      "Episode 50\tAverage Score: -123.90\n",
      "Episode 60\tAverage Score: -118.01\n",
      "Episode 70\tAverage Score: -113.29\n",
      "Episode 80\tAverage Score: -108.76\n",
      "Episode 90\tAverage Score: -104.67\n",
      "Episode 100\tAverage Score: -100.61\n",
      "Episode 110\tAverage Score: -90.19\n",
      "Episode 120\tAverage Score: -81.91\n",
      "Episode 130\tAverage Score: -74.45\n",
      "Episode 140\tAverage Score: -67.40\n",
      "Episode 150\tAverage Score: -59.55\n",
      "Episode 160\tAverage Score: -51.74\n",
      "Episode 170\tAverage Score: -42.70\n",
      "Episode 180\tAverage Score: -33.24\n",
      "Episode 190\tAverage Score: -23.72\n",
      "Episode 200\tAverage Score: -14.21\n",
      "Episode 210\tAverage Score: -3.94\n",
      "Episode 220\tAverage Score: 6.05\n",
      "Episode 230\tAverage Score: 15.39\n",
      "Episode 240\tAverage Score: 24.41\n",
      "Episode 250\tAverage Score: 33.38\n",
      "Episode 260\tAverage Score: 41.64\n",
      "Episode 270\tAverage Score: 47.91\n",
      "Episode 280\tAverage Score: 54.41\n",
      "Episode 290\tAverage Score: 60.86\n",
      "Episode 300\tAverage Score: 67.00\n",
      "Episode 310\tAverage Score: 73.23\n",
      "Episode 320\tAverage Score: 80.63\n",
      "Episode 330\tAverage Score: 86.67\n",
      "Episode 340\tAverage Score: 95.33\n",
      "Episode 350\tAverage Score: 102.96\n",
      "Episode 360\tAverage Score: 110.29\n",
      "Episode 370\tAverage Score: 120.75\n",
      "Episode 380\tAverage Score: 128.97\n",
      "Episode 390\tAverage Score: 137.46\n",
      "Episode 400\tAverage Score: 144.92\n",
      "Episode 410\tAverage Score: 152.44\n",
      "Episode 420\tAverage Score: 158.40\n",
      "Episode 430\tAverage Score: 166.42\n",
      "Episode 440\tAverage Score: 172.60\n",
      "Episode 450\tAverage Score: 180.07\n",
      "Episode 460\tAverage Score: 187.61\n",
      "Episode 470\tAverage Score: 191.22\n",
      "Episode 480\tAverage Score: 196.09\n",
      "Episode 490\tAverage Score: 200.63\n",
      "Episode 500\tAverage Score: 206.34\n",
      "Episode 510\tAverage Score: 210.28\n",
      "Episode 520\tAverage Score: 214.45\n",
      "Episode 530\tAverage Score: 217.25\n",
      "Episode 540\tAverage Score: 219.44\n",
      "Episode 550\tAverage Score: 219.40\n",
      "Episode 560\tAverage Score: 219.44\n",
      "Episode 570\tAverage Score: 220.96\n",
      "Episode 580\tAverage Score: 221.30\n",
      "Episode 590\tAverage Score: 221.81\n",
      "Episode 600\tAverage Score: 220.69\n",
      "Episode 610\tAverage Score: 219.58\n",
      "Episode 620\tAverage Score: 218.71\n",
      "Episode 630\tAverage Score: 217.75\n",
      "Episode 640\tAverage Score: 216.04\n",
      "Episode 650\tAverage Score: 215.76\n",
      "Episode 660\tAverage Score: 215.42\n",
      "Episode 670\tAverage Score: 216.63\n",
      "Episode 680\tAverage Score: 217.69\n",
      "Episode 690\tAverage Score: 217.26\n",
      "Episode 700\tAverage Score: 218.66\n",
      "Episode 710\tAverage Score: 219.12\n",
      "Episode 720\tAverage Score: 219.85\n",
      "Episode 730\tAverage Score: 220.57\n",
      "Episode 740\tAverage Score: 222.30\n",
      "Episode 750\tAverage Score: 224.42\n",
      "Episode 760\tAverage Score: 226.71\n",
      "Episode 770\tAverage Score: 226.32\n",
      "Episode 780\tAverage Score: 226.23\n",
      "Episode 790\tAverage Score: 226.88\n",
      "Episode 800\tAverage Score: 224.49\n",
      "Episode 810\tAverage Score: 220.01\n",
      "Episode 820\tAverage Score: 214.79\n",
      "Episode 830\tAverage Score: 214.39\n",
      "Episode 840\tAverage Score: 212.55\n",
      "Episode 850\tAverage Score: 210.25\n",
      "Episode 860\tAverage Score: 208.29\n",
      "Episode 870\tAverage Score: 206.71\n",
      "Episode 880\tAverage Score: 206.21\n",
      "Episode 890\tAverage Score: 206.11\n",
      "Episode 900\tAverage Score: 207.75\n",
      "Episode 910\tAverage Score: 213.49\n",
      "Episode 920\tAverage Score: 219.18\n",
      "Episode 930\tAverage Score: 220.42\n",
      "Episode 940\tAverage Score: 223.01\n",
      "Episode 950\tAverage Score: 224.95\n",
      "Episode 960\tAverage Score: 227.55\n",
      "Episode 970\tAverage Score: 230.86\n",
      "Episode 980\tAverage Score: 233.86\n",
      "Episode 990\tAverage Score: 236.87\n",
      "Reached 1000000.0 timesteps. Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Retrain the agent with the best hyperparameters\n",
    "best_agent = DQNAgent(\n",
    "    state_size=state_size,\n",
    "    action_size=action_size,\n",
    "    buffer_size=12728,\n",
    "    batch_size=224,\n",
    "    gamma=0.950000000000000,\n",
    "    lr=0.0006304159219839015,\n",
    "    tau=0.0007586575243168811,\n",
    "    update_every=3,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "\n",
    "eps_decay = 0.995  # Replace with a value appropriate for your experiment\n",
    "\n",
    "# Train the agent (replace train_agent with dqn or another defined training function)\n",
    "best_scores = dqn(\n",
    "    n_episodes=2000,\n",
    "    max_t=1000,\n",
    "    eps_start=1.0,\n",
    "    eps_end=0.01,\n",
    "    eps_decay=eps_decay,\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "torch.save(best_agent.qnetwork_local.state_dict(), \"dqn_lunarlander_best.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more plots (experimental couldnt run this till now since i havent done a full optuna study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_optimization_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Optimization History\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m fig \u001b[38;5;241m=\u001b[39m \u001b[43mplot_optimization_history\u001b[49m(study)\n\u001b[0;32m      4\u001b[0m fig\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Hyperparameter Importance\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_optimization_history' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Optimization History\n",
    "fig = plot_optimization_history(study)\n",
    "fig.show()\n",
    "\n",
    "# Hyperparameter Importance\n",
    "fig = plot_param_importances(study)\n",
    "fig.show()\n",
    "\n",
    "# Parallel Coordinate Plot\n",
    "fig = plot_parallel_coordinate(study)\n",
    "fig.show()\n",
    "\n",
    "# Slice Plot\n",
    "fig = plot_slice(study)\n",
    "fig.show()\n",
    "\n",
    "# Save the study results for further analysis\n",
    "study_df = study.trials_dataframe()\n",
    "study_df.to_csv(\"optuna_dqn_results.csv\", index=False)\n",
    "\n",
    "# Save the best model path\n",
    "best_model_path = \"best_model.pth\"\n",
    "if os.path.exists(best_model_path):\n",
    "    print(f\"Loading best model from {best_model_path}\")\n",
    "    best_agent = DQNAgent(\n",
    "        state_size=env.observation_space.shape[0],\n",
    "        action_size=env.action_space.n,\n",
    "        buffer_size=study.best_params[\"buffer_size\"],\n",
    "        batch_size=study.best_params[\"batch_size\"],\n",
    "        gamma=study.best_params[\"gamma\"],\n",
    "        lr=study.best_params[\"lr\"],\n",
    "        tau=study.best_params[\"tau\"],\n",
    "        update_every=study.best_params[\"update_every\"],\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    )\n",
    "    best_agent.qnetwork_local.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "# Print study insights\n",
    "print(\"\\nTop 5 Trials:\")\n",
    "top_trials = sorted(study.trials, key=lambda t: t.value)[:5]\n",
    "for trial in top_trials:\n",
    "    print(f\"Trial {trial.number}: Value={-trial.value}, Params={trial.params}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "QAN7B0_HCVZC",
    "BqPKw3jt_pG5"
   ],
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
